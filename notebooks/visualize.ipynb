{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!od3d platform run -p torque -c \"od3d dataset setup -d co3dv1_zsp_10s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!od3d platform run -p torque -c \"od3d dataset extract-meta -d co3dv1_zsp_10s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!od3d platform run -p torque -c \"od3d dataset preprocess -d co3dv1_zsp_10s\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "from typing import List, Union\n",
    "from od3d.datasets.co3dv1 import CO3Dv1\n",
    "from od3d.cv.visual.show import  show_scene2d , show_scene ,show_pcl_via_open3d\n",
    "from od3d.datasets.co3dv1.dataset import CO3Dv1_Sequence\n",
    "from od3d.cv.geometry.transform import transf3d_broadcast\n",
    "from od3d.cv.cluster.embed import tsne, pca \n",
    "import torch\n",
    "import matplotlib\n",
    "import open3d as o3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence_data(sequences: List[CO3Dv1_Sequence] , index: int):\n",
    "    sequence = sequences[index]\n",
    "    mesh_verts = sequence.get_mesh().verts_ncds.clone()\n",
    "    cams_tform4x4_world, cams_intr4x4, cams_imgs = sequence.get_cams(cams_count=-1)\n",
    "    #mesh.verts = transf3d_broadcast(mesh.verts),#sequence.zsp_labeled_cuboid_ref_tform_obj)\n",
    "    sequence_dict = {\n",
    "        'feats': sequence.get_mesh_feats(),\n",
    "        'viewpoints': sequence.get_mesh_feats_viewpoint(),\n",
    "        'cams_intr4x4': cams_intr4x4,\n",
    "        'cams_tform4x4_world': cams_tform4x4_world,\n",
    "        'pts3d': mesh_verts ,\n",
    "        'imgs': cams_imgs}\n",
    "    return sequence_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_scene2d(\n",
    "        pts2d: Union[torch.Tensor, List[torch.Tensor]]=None,\n",
    "        pts2d_names: List[str]=None,\n",
    "        pts2d_colors: Union[torch.Tensor, List]=None,\n",
    "        pts2d_length: int=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pts2d (Union[torch.Tensor, List[torch.Tensor]]): PxNx2 or List(Npx2)\n",
    "        pts2d_names (List[str]): (P,)\n",
    "        pts2d_colors (Union[torch.Tensor, List]): Px2x3 or List(3)\n",
    "    Returns:\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    # scatter plot 2d with legend and colors\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib\n",
    "    matplotlib.use(\"TkAgg\")\n",
    "\n",
    "    # scatter plot 2d with legend and colors\n",
    "    fig, ax = plt.subplots(len(pts2d), 1)\n",
    "    if pts2d is not None:\n",
    "        for i, pts2d_i in enumerate(pts2d):\n",
    "            if pts2d_colors is not None:\n",
    "                pts2d_colors_i = pts2d_colors[i]\n",
    "            #else:\n",
    "              #pts2d_colors_i = get_colors(len(pts2d))[i]\n",
    "            \n",
    "\n",
    "            \n",
    "            if pts2d_length > 0:\n",
    "                colours = pts2d_colors_i.detach().cpu().numpy()\n",
    "                ax[i].scatter(pts2d_i[:pts2d_length, 0].detach().cpu().numpy(), pts2d_i[:pts2d_length, 1].detach().cpu().numpy(),\n",
    "                               c=colours[:pts2d_length], marker = 'x')\n",
    "                ax[i].scatter(pts2d_i[pts2d_length:, 0].detach().cpu().numpy(), pts2d_i[pts2d_length:, 1].detach().cpu().numpy(),\n",
    "                               c=colours[pts2d_length:], marker = 'o')\n",
    "            else:\n",
    "                ax[i].scatter(pts2d_i[:, 0].detach().cpu().numpy(), pts2d_i[:, 1].detach().cpu().numpy(), c=pts2d_colors_i.detach().cpu().numpy())\n",
    "            if pts2d_names is not None:\n",
    "                ax[i].title.set_text(pts2d_names[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/heisenberg/Thesis_repo/od3d/venv_od3d/lib/python3.8/site-packages/hydra/_internal/defaults_list.py:251: UserWarning: In 'defaults': Defaults list is missing `_self_`. See https://hydra.cc/docs/1.2/upgrades/1.0_to_1.1/default_composition_order for more information\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "categories: ['bicycle', 'toytruck', 'toytrain', 'teddybear', 'car', 'toybus', 'motorcycle', 'keyboard', 'handbag', 'remote', 'toyplane', 'toilet', 'hairdryer', 'mouse', 'toaster', 'hydrant', 'chair', 'laptop', 'book', 'backpack']\n"
     ]
    }
   ],
   "source": [
    "sequence_list = [0,1,2]\n",
    "merge = True\n",
    "co3d = CO3Dv1.create_by_name('co3dv1_zsp_10s', config={'preprocess' : {'tform_obj': {'enabled': False}},'mesh_feats' :{'enabled':False},'mesh_feats_dist' :{'enabled':False}}) #, config={'categories': [category], 'aligned_name': aligned_name, 'sequences_count_max_per_category': sequences_count}) # co3d_no_zsp_20s_aligned #co3d_5s_no_zsp_labeled 'co3d_50s_no_zsp_aligned' 'co3dv1_10s_zsp_aligned' 'co3d_10s_zsp_aligned' 'co3dv1_10s_zsp_unlabeled'\n",
    "categories = co3d.categories\n",
    "sequences = co3d.get_sequences()\n",
    "\n",
    "seq1 = get_sequence_data(sequences,0) #\n",
    "seq2 = get_sequence_data(sequences,1) \n",
    "\n",
    "if merge:\n",
    "    seq_feats = seq1[\"feats\"] + seq2[\"feats\"]\n",
    "print('categories:', categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq1_feats = seq1[\"feats\"]\n",
    "seq2_feats = seq2[\"feats\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_feats_padded = torch.nn.utils.rnn.pad_sequence(seq_feats , batch_first=True, padding_value=torch.nan)\n",
    "seq_feats_padded_mask = (~seq_feats_padded.isnan().all(dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA 2D and 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_feats_embed = pca(seq_feats_padded[seq_feats_padded_mask], C=2)\n",
    "seq_feats_embed = seq_feats_embed.detach().cpu()\n",
    "seq_feats_embed_3d = pca(seq_feats_padded[seq_feats_padded_mask], C=3)\n",
    "seq_feats_embed_3d = seq_feats_embed_3d.detach().cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE 2D and 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_feats_embed = tsne(seq_feats_padded[seq_feats_padded_mask], C=2)\n",
    "seq_feats_embed = seq_feats_embed.detach().cpu()\n",
    "seq_feats_embed_3d = tsne(seq_feats_padded[seq_feats_padded_mask], C=3)\n",
    "seq_feats_embed_3d = seq_feats_embed_3d.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_colors_padded = torch.zeros(size=seq_feats_padded.shape[:-1] + (4,), dtype=torch.float32)\n",
    "seq_colors_padded[:, :, 3] = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "seq_colors_padded_verts = seq_colors_padded.clone()\n",
    "if merge:\n",
    "    seq_colors_padded_verts[:len(seq1_feats), :, :3] = seq1['pts3d'][:, None, :3]\n",
    "    seq_colors_padded_verts[len(seq1_feats):, :, :3] = seq2['pts3d'][:, None, :3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if merge:\n",
    "    seq_feats_viewpoints = seq1['viewpoints'] + seq2['viewpoints']\n",
    "else:\n",
    "    seq_feats_viewpoints = seq1['viewpoints']\n",
    "\n",
    "seq_feats_viewpoints_padded = torch.nn.utils.rnn.pad_sequence(seq_feats_viewpoints , batch_first=True,\n",
    "                                                     padding_value=torch.nan)\n",
    "seq_feats_viewpoints_padded = (seq_feats_viewpoints_padded - seq_feats_viewpoints_padded[seq_feats_padded_mask].min(dim=0).values[None, None]) \\\n",
    "                                / (seq_feats_viewpoints_padded[seq_feats_padded_mask].max(dim=0).values[None, None] - seq_feats_viewpoints_padded[seq_feats_padded_mask].min(dim=0).values[None, None])\n",
    "\n",
    "seq1_colors_padded_viewpoint = seq_colors_padded.clone()\n",
    "if merge:\n",
    "    seq1_colors_padded_viewpoint[:, :, :3] = seq_feats_viewpoints_padded[:, :, :3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9484"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq1_embed_length =sum([seq1_feats[i].shape[0] for i in range(len(seq1_feats))])\n",
    "seq1_embed_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_scene2d(pts2d=[seq_feats_embed[:], seq_feats_embed[:]],\n",
    "             pts2d_colors=[seq_colors_padded_verts[seq_feats_padded_mask], seq1_colors_padded_viewpoint[seq_feats_padded_mask]],\n",
    "             pts2d_length= seq1_embed_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18822, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colours = seq_colors_padded_verts[seq_feats_padded_mask].numpy()[:,:3]\n",
    "colours\n",
    "seq_feats_embed_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backend TkAgg is interactive backend. Turning interactive mode on.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to cast Python instance of type <class 'numpy.float32'> to C++ type '?' (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/heisenberg/Thesis_repo/od3d/notebooks/visualize.ipynb Cell 21\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/heisenberg/Thesis_repo/od3d/notebooks/visualize.ipynb#X25sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m show_scene(pts3d\u001b[39m=\u001b[39;49mseq_feats_embed_3d[:], pts3d_colors\u001b[39m=\u001b[39;49mcolours)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/heisenberg/Thesis_repo/od3d/notebooks/visualize.ipynb#X25sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m              \u001b[39m#pts3d_colors=[seq_colors_padded_verts[seq_feats_padded_mask], seq1_colors_padded_viewpoint[seq_feats_padded_mask]])\u001b[39;00m\n",
      "File \u001b[0;32m~/Thesis_repo/od3d/src/od3d/cv/visual/show.py:301\u001b[0m, in \u001b[0;36mshow_scene\u001b[0;34m(cams_tform4x4_world, cams_intr4x4, cams_imgs, cams_names, cams_imgs_resize, cams_imgs_depth_scale, cams_show_wireframe, pts3d, pts3d_names, pts3d_colors, pts3d_normals, lines3d, lines3d_names, lines3d_colors, meshes, meshes_names, meshes_colors, meshes_add_translation, pts3d_add_translation, fpath, return_visualization, viewpoints_count, dtype, H, W, device, meshes_as_wireframe, crop_white_border)\u001b[0m\n\u001b[1;32m    299\u001b[0m     _pts3d_i[:, \u001b[39m0\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m x_offset\n\u001b[1;32m    300\u001b[0m     x_offset \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m x_offset_delta_next\n\u001b[0;32m--> 301\u001b[0m pts3d_i_o3d\u001b[39m.\u001b[39mpoints \u001b[39m=\u001b[39m open3d\u001b[39m.\u001b[39;49mutility\u001b[39m.\u001b[39;49mVector3dVector(_pts3d_i\u001b[39m.\u001b[39;49mdetach()\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39;49mnumpy())\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m pts3d_normals \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(pts3d_normals) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m pts3d_normals[i] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    304\u001b[0m     pts3d_i_o3d\u001b[39m.\u001b[39mnormals \u001b[39m=\u001b[39m open3d\u001b[39m.\u001b[39mutility\u001b[39m.\u001b[39mVector3dVector(pts3d_normals[i]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Unable to cast Python instance of type <class 'numpy.float32'> to C++ type '?' (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)"
     ]
    }
   ],
   "source": [
    "show_scene(pts3d=seq_feats_embed_3d[:], pts3d_colors=colours)\n",
    "             #pts3d_colors=[seq_colors_padded_verts[seq_feats_padded_mask], seq1_colors_padded_viewpoint[seq_feats_padded_mask]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_od3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
